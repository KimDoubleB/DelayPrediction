{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import urllib.request\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDT_YY</th>\n",
       "      <th>SDT_MM</th>\n",
       "      <th>SDT_DD</th>\n",
       "      <th>SDT_DY</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ODP</th>\n",
       "      <th>FLO</th>\n",
       "      <th>FLT</th>\n",
       "      <th>REG</th>\n",
       "      <th>AOD</th>\n",
       "      <th>IRR</th>\n",
       "      <th>STT</th>\n",
       "      <th>ATT</th>\n",
       "      <th>DLY</th>\n",
       "      <th>DRR</th>\n",
       "      <th>CNL</th>\n",
       "      <th>CNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>A</td>\n",
       "      <td>A1901</td>\n",
       "      <td>SEw3Nzc2</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:10</td>\n",
       "      <td>6:18</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>A</td>\n",
       "      <td>A1905</td>\n",
       "      <td>SEw4MjM2</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:15</td>\n",
       "      <td>6:25</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>L</td>\n",
       "      <td>L1751</td>\n",
       "      <td>SEw4MjM3</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:20</td>\n",
       "      <td>6:30</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>F</td>\n",
       "      <td>F1201</td>\n",
       "      <td>SEw4MjA3</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:25</td>\n",
       "      <td>6:34</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>A</td>\n",
       "      <td>A1900</td>\n",
       "      <td>SEw3NzAz</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:30</td>\n",
       "      <td>6:37</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDT_YY  SDT_MM  SDT_DD SDT_DY   ARP   ODP FLO    FLT       REG AOD IRR  \\\n",
       "0    2017       1       1      일  ARP1  ARP3   A  A1901  SEw3Nzc2   D   N   \n",
       "1    2017       1       1      일  ARP1  ARP3   A  A1905  SEw4MjM2   D   N   \n",
       "2    2017       1       1      일  ARP1  ARP3   L  L1751  SEw4MjM3   D   N   \n",
       "3    2017       1       1      일  ARP1  ARP3   F  F1201  SEw4MjA3   D   N   \n",
       "4    2017       1       1      일  ARP3  ARP1   A  A1900  SEw3NzAz   D   N   \n",
       "\n",
       "    STT   ATT DLY  DRR CNL  CNR  \n",
       "0  6:10  6:18   N  NaN   N  NaN  \n",
       "1  6:15  6:25   N  NaN   N  NaN  \n",
       "2  6:20  6:30   N  NaN   N  NaN  \n",
       "3  6:25  6:34   N  NaN   N  NaN  \n",
       "4  6:30  6:37   N  NaN   N  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin = pd.read_csv('AFSNT.csv', encoding=\"cp949\")\n",
    "origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin.rename(columns={'SDT_YY':'Year', 'SDT_MM':'Month', 'SDT_DD':'DAY'}, inplace=True)\n",
    "#### 'STT'의 시간단위만 추출해 'hour'에 저장\n",
    "origin['hour']=pd.to_datetime(origin['STT'],format= '%H:%M').dt.hour\n",
    "\n",
    "####'SDT_DY'를 categorical 데이터로 수정\n",
    "one_hot_dy = pd.get_dummies(origin['SDT_DY'])\n",
    "origin = origin.drop(['SDT_DY'],axis = 1)\n",
    "origin = origin.join(one_hot_dy)\n",
    "origin.rename(columns={\"일\":\"Sun\",\"월\":\"Mon\",\"화\":\"Tue\",\"수\":\"Wed\",\"목\":\"Thu\",\"금\":\"Fri\",\"토\":\"SAT\",\"일\":\"Sun\"                    \n",
    "                  }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 987709 entries, 0 to 987708\n",
      "Data columns (total 24 columns):\n",
      "Year     987709 non-null int64\n",
      "Month    987709 non-null int64\n",
      "DAY      987709 non-null int64\n",
      "ARP      987709 non-null object\n",
      "ODP      987709 non-null object\n",
      "FLO      987709 non-null object\n",
      "FLT      987709 non-null object\n",
      "REG      987251 non-null object\n",
      "AOD      987709 non-null object\n",
      "IRR      987709 non-null object\n",
      "STT      987709 non-null object\n",
      "ATT      979461 non-null object\n",
      "DLY      987709 non-null object\n",
      "DRR      119917 non-null object\n",
      "CNL      987709 non-null object\n",
      "CNR      3018 non-null object\n",
      "hour     987709 non-null int64\n",
      "Fri      987709 non-null uint8\n",
      "Thu      987709 non-null uint8\n",
      "Wed      987709 non-null uint8\n",
      "Mon      987709 non-null uint8\n",
      "Sun      987709 non-null uint8\n",
      "SAT      987709 non-null uint8\n",
      "Tue      987709 non-null uint8\n",
      "dtypes: int64(4), object(13), uint8(7)\n",
      "memory usage: 134.7+ MB\n"
     ]
    }
   ],
   "source": [
    "origin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 한 자리수 데이터를 앞에 '0'을 붙여 두 자리로 변환\n",
    "def changeDate(data):\n",
    "    data=str(data)\n",
    "    if len(data)==1:\n",
    "        data=\"0\"+data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####군공항을 제외한 날씨 데이터를 다운받는 함수(공항공사 데이터)\n",
    "\n",
    "def downloadAirport(yy,mm,area):\n",
    "    mm=changeDate(mm)\n",
    "    yy=str(yy)\n",
    "    url='http://amoapi.kma.go.kr/amoApi/air_stcs?icao='+area+'&yyyymm='+yy+mm\n",
    "    response = urllib.request.urlopen(url)\n",
    "    cr = csv.reader(codecs.iterdecode(response, 'utf-8'))\n",
    "    \n",
    "    #### url로 읽어와 데이터 프레임에 저장\n",
    "    temp=[]\n",
    "    for line in cr:\n",
    "        temp.append(line)\n",
    "    \n",
    "    labels=temp[0]\n",
    "    weather=pd.DataFrame.from_records(temp[1:],columns=labels)\n",
    "    \n",
    "    weather[\"TM\"]=weather[\"TM\"].astype(\"str\")\n",
    "\n",
    "    weather[\"Year\"]=weather[\"TM\"].str.slice(0,4)\n",
    "    weather[\"Month\"]=weather[\"TM\"].str.slice(4,6)\n",
    "    weather[\"DAY\"]=weather[\"TM\"].str.slice(6,8)\n",
    "    hh=weather[\"TM\"].str.slice(8,10)\n",
    "    weather['hour']=hh\n",
    "\n",
    "    weather['hour']= weather['hour'].astype('int')\n",
    "    weather['hour']=weather['hour'].replace(24,0)\n",
    "    \n",
    "    #### 분석에 필요하지 않은 column 삭제\n",
    "    weather.drop(columns=[\"TM\"], axis=1, inplace=True)\n",
    "    weather.drop(columns=[\"WD\",\"WS_GST\",\"RVR1\",\"RVR2\",\"RVR3\",\"RVR4\",\"CLA_1LYR\"\n",
    "               ,\"BASE_1LYR\",\"CLF_1LYR\",\"CLA_2LYR\",\"BASE_2LYR\",\"CLF_2LYR\",\n",
    "               \"CLA_3LYR\",\"BASE_3LYR\",\"CLF_3LYR\",\"CLA_4LYR\",\"BASE_4LYR\",\"CLF_4LYR\"], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    #### 기록이 안 되어 있는 데이터에 '0'을 채워줌\n",
    "    weather=weather.fillna(0)\n",
    "    weather[\"Year\"]=weather[\"Year\"].astype(\"int\")\n",
    "    weather[\"Month\"]=weather[\"Month\"].astype(\"int\")\n",
    "    weather[\"DAY\"]=weather[\"DAY\"].astype(\"int\")\n",
    "    \n",
    "    return weather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 항공데이터에서 제공하지 않는 군공항 데이터를 기상청 날씨데이터를 사용해 다운받는 함수(기상청 csv)\n",
    "def downloadWeather(year):\n",
    "    filename=\"data/\"+str(year)+\".csv\"\n",
    "    weather=pd.read_csv(filename,encoding=\"cp949\")\n",
    "    \n",
    "    #### 일시의 데이트타입과 시간을 따로 저장\n",
    "    weather[\"일시\"] = weather[\"일시\"].astype('str')\n",
    "    date=weather[\"일시\"].str.split(expand=True)\n",
    "    day=date[0].str.split(\"-\",expand=True)\n",
    "    \n",
    "    weather[\"Year\"]=day[0]\n",
    "    weather[\"Month\"]=day[1]\n",
    "    weather[\"DAY\"]=day[2]\n",
    "    \n",
    "    \n",
    "    weather[\"hour\"]=date[1]\n",
    "    \n",
    "    #### 일시 drop(변경 전 데이터)\n",
    "    weather.drop(columns=['일시'], axis=1, inplace=True)\n",
    "    #### 분석에 필요하지 않은 column 삭제\n",
    "    weather = weather.drop(['지면온도(°C)',\"지면온도 QC플래그\",\"5cm 지중온도(°C)\",\"10cm 지중온도(°C)\",\"20cm 지중온도(°C)\",\"기온 QC플래그\",\n",
    "                            \"강수량 QC플래그\",\"풍속 QC플래그\",\"풍향(16방위)\",\"풍향 QC플래그\",\"습도 QC플래그\",\"현지기압 QC플래그\",\n",
    "                            \"해면기압 QC플래그\",\"중하층운량(10분위)\",\"운형(운형약어)\",\"최저운고(100m )\",\"지면상태(지면상태코드)\",\n",
    "                           \"적설(cm)\",\"3시간신적설(cm)\", \"30cm 지중온도(°C)\",\"일조(hr)\",\"일조 QC플래그\",\"일사(MJ/m2)\"],axis = 1)\n",
    "    \n",
    "    #### 한글을 사용함으로써 발생하는 오류를 방지하기 위해 column명들을 영어로 rename\n",
    "    weather.rename(columns={\"지점\" : \"area\", \"기온(°C)\":\"temp\" ,\"강수량(mm)\":\"rain\", \"풍속(m/s)\":\"windSpeed\",\n",
    "                            \"습도(%)\":\"hum\",\"증기압(hPa)\":\"Vapor\",\"이슬점온도(°C)\":\"dew\",\"현지기압(hPa)\":\"hpa\",\n",
    "                            \"해면기압(hPa)\":\"seeHpa\",\"시정(10m)\":\"visible\",\"전운량(10분위)\":\"cloudTotal\",\n",
    "                            \"현상번호(국내식)\":\"weatherCode\"}, inplace=True)\n",
    "    \n",
    "    #### merge시에 타입이 같아야 하므로 데이터타입을 int형으로 변환\n",
    "    weather[\"hour\"]=weather[\"hour\"].astype(\"str\")\n",
    "    weather[\"hour\"]=weather[\"hour\"].str.split(\":\",expand=True)[0]\n",
    "    weather[\"hour\"]=weather[\"hour\"].astype(\"int\")\n",
    "    \n",
    "    weather[\"Year\"]=weather[\"Year\"].astype(\"int\")\n",
    "    weather[\"Month\"]=weather[\"Month\"].astype(\"int\")\n",
    "    weather[\"DAY\"]=weather[\"DAY\"].astype(\"int\")\n",
    "    \n",
    "    #### 기록이 안 되어 있는 데이터에 '0'을 채워줌    \n",
    "    weather=weather.fillna(0)\n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 군공항을 제외한 항공들의 날씨 데이터와 기상 정보를 merge하는 함수\n",
    "def mergeAirportData():\n",
    "    df_all=pd.DataFrame()\n",
    "    #### 군공항을 제외한 항공들만 저장\n",
    "    temp=origin[(origin.ARP==\"ARP1\") | (origin.ARP==\"ARP3\")| (origin.ARP==\"ARP5\") | (origin.ARP==\"ARP7\") \n",
    "                | (origin.ARP==\"ARP9\")| (origin.ARP==\"ARP10\") ]\n",
    "    \n",
    "    elements,count=np.unique(temp[\"ARP\"],return_counts=True)\n",
    "    \n",
    "    #### 각각의 공항에 대하여 월별로 데이터를 찾아 merge하고 DataFrame형태로 저장하는 loop문\n",
    "    for i in range(len(elements)):\n",
    "        df_areaD=pd.DataFrame()\n",
    "        arp=elements[i]\n",
    "        area={\"ARP1\":\"RKSS\",\"ARP3\":\"RKPC\",\"ARP5\":\"RKPU\",\n",
    "              \"ARP7\":\"RKJB\",\"ARP9\":\"RKJY\",\"ARP10\":\"RKNY\"}.get(arp)\n",
    "        df_areaD=temp[temp[\"ARP\"]==arp]\n",
    "        \n",
    "        for j in range(3):\n",
    "            year=2017+j\n",
    "            for k in range(12):\n",
    "                #### 2019년은 데이터가 6월까지만 존재함\n",
    "                if year==2019:\n",
    "                    if k>=6:\n",
    "                        break;\n",
    "                month=1+k\n",
    "                df_date=df_areaD[(df_areaD[\"Year\"]==year) & (df_areaD[\"Month\"]==month)]\n",
    "                weather=downloadAirport(year,month,area)\n",
    "                df_new=pd.merge(df_areaD,weather,on=[\"Year\",\"Month\",\"DAY\",\"hour\"])\n",
    "                \n",
    "                if i==0 and j==0 and k==0:\n",
    "                    df_all=df_new.copy()\n",
    "                else:\n",
    "                    df_all=df_all.append(df_new)\n",
    "                    \n",
    "    #### 기상청데이터와 연결 하기 위해 rename                \n",
    "    df_all.rename(columns={'WSPD':'windSpeed','VIS':\"visible\",\"TMP\":\"temp\",\n",
    "                      \"TD\":\"dew\",'PS':'hpa','PA':'seeHpa','RN':'rain','HM':'hum',\n",
    "                        'CA_TOT':'cloudTotal','WC':\"weatherCode\"}, inplace=True)\n",
    "    \n",
    "    \n",
    "    #### 기상청에서 받아온 파일과 함께 저장하기 위해 항공공사의 데이터의 단위를 조정함\n",
    "    df_all['temp']=df_all['temp'].astype(\"float\")/10\n",
    "    df_all['hpa']=df_all['hpa'].astype(\"float\")/10\n",
    "    df_all['seeHpa']=df_all['seeHpa'].astype(\"float\")/10\n",
    "    df_all['dew']=df_all['dew'].astype(\"float\")/10\n",
    "    df_all['windSpeed']=df_all['windSpeed'].astype(\"float\")*1852/3600\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 군공항에 대해 기상청을 통해 불러온 날씨 데이터와 기상 정보를 merge하는 함수\n",
    "def mergeWeatherData():\n",
    "    temp=origin[(origin.ARP==\"ARP2\") | (origin.ARP==\"ARP4\")| (origin.ARP==\"ARP6\") | (origin.ARP==\"ARP8\") | (origin.ARP==\"ARP11\")\n",
    "                | (origin.ARP==\"ARP12\")| (origin.ARP==\"ARP13\")| (origin.ARP==\"ARP14\")|(origin.ARP==\"ARP15\")]\n",
    "    \n",
    "    elements,count=np.unique(temp[\"ARP\"],return_counts=True)\n",
    "    \n",
    "    #### 각각의 공항에 대하여 연별로 데이터를 찾아 merge하고 저장하는 loop문\n",
    "    for i in range(3):\n",
    "        df_areaD=pd.DataFrame()\n",
    "        year=2017+i\n",
    "        weather=downloadWeather(year)\n",
    "        df_yearD=origin[origin[\"Year\"]==year]\n",
    "        for j in range(len(elements)):\n",
    "            arp=elements[j]\n",
    "            area={\"ARP2\":159,\"ARP4\":143,\"ARP6\":131, \"ARP8\":156,\n",
    "                  \"ARP11\":138,\"ARP12\":192, \"ARP13\":140,\"ARP14\":114,\"ARP15\":112}.get(arp)\n",
    "            \n",
    "            df_areaD=df_yearD[df_yearD[\"ARP\"]==arp]\n",
    "            df_new=pd.DataFrame()\n",
    "            weatherT=weather[weather[\"area\"]==area]\n",
    "           \n",
    "            df_new=pd.merge(df_areaD,weatherT,on=[\"DAY\",\"hour\",\"Year\",\"Month\"])\n",
    "        \n",
    "            if i==0 and j==0:\n",
    "                df_all=df_new.copy()\n",
    "            else:\n",
    "                df_all=df_all.append(df_new)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport=mergeAirportData()\n",
    "df_nonAirport=mergeWeatherData()\n",
    "\n",
    "df_weather=df_airport.append(df_nonAirport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.drop(['area','Vapor', 'hour'], axis = 1, inplace=True)\n",
    "#### 데이터가 입력되어있지 않은 것들을 '0'으로 대체함\n",
    "df_weather['visible']= df_weather['visible'].replace(\"\", 0)\n",
    "df_weather['hum']= df_weather['hum'].replace(\"\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 기상정보와 날씨 데이터를 합친 DataFrame을 파일로 저장\n",
    "df_weather.to_csv(\"weatherFinal.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AOD</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ATT</th>\n",
       "      <th>CNL</th>\n",
       "      <th>CNR</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DLY</th>\n",
       "      <th>DRR</th>\n",
       "      <th>FLO</th>\n",
       "      <th>FLT</th>\n",
       "      <th>...</th>\n",
       "      <th>cloudTotal</th>\n",
       "      <th>dew</th>\n",
       "      <th>hpa</th>\n",
       "      <th>hum</th>\n",
       "      <th>rain</th>\n",
       "      <th>seeHpa</th>\n",
       "      <th>temp</th>\n",
       "      <th>visible</th>\n",
       "      <th>weatherCode</th>\n",
       "      <th>windSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>6:18</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>A1901</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.543333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>6:25</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>A1905</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.543333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>6:30</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>L1751</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.543333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>6:34</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F1201</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.543333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>6:38</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>H1101</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.543333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  AOD   ARP   ATT CNL  CNR  DAY DLY  DRR FLO    FLT  ...  cloudTotal  dew  \\\n",
       "0   D  ARP1  6:18   N  NaN    1   N  NaN   A  A1901  ...         3.0 -5.7   \n",
       "1   D  ARP1  6:25   N  NaN    1   N  NaN   A  A1905  ...         3.0 -5.7   \n",
       "2   D  ARP1  6:30   N  NaN    1   N  NaN   L  L1751  ...         3.0 -5.7   \n",
       "3   D  ARP1  6:34   N  NaN    1   N  NaN   F  F1201  ...         3.0 -5.7   \n",
       "4   D  ARP1  6:38   N  NaN    1   N  NaN   H  H1101  ...         3.0 -5.7   \n",
       "\n",
       "      hpa   hum rain  seeHpa  temp visible  weatherCode  windSpeed  \n",
       "0  1029.0  80.0  NaN  1027.4  -2.5   250.0         10.0   1.543333  \n",
       "1  1029.0  80.0  NaN  1027.4  -2.5   250.0         10.0   1.543333  \n",
       "2  1029.0  80.0  NaN  1027.4  -2.5   250.0         10.0   1.543333  \n",
       "3  1029.0  80.0  NaN  1027.4  -2.5   250.0         10.0   1.543333  \n",
       "4  1029.0  80.0  NaN  1027.4  -2.5   250.0         10.0   1.543333  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('weatherFinal.csv', encoding=\"cp949\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[df.IRR != \"Y\"] # 부정기 없애기 \n",
    "df = df[df.CNL != \"Y\"]\n",
    "\n",
    "#### 비행기 취소와 관련된 Column 삭제\n",
    "df.drop(columns=['CNL', 'CNR'], axis=1, inplace=True)\n",
    "\n",
    "#### AFSNT_DLY 파일에는 존재하지 않아 학습에 사용할 수 없는 column 삭제\n",
    "df.drop(columns=['REG', 'IRR'], axis=1, inplace=True)\n",
    "\n",
    "#### 딜레이 이유 (나중에 쓰일 듯)\n",
    "df.drop(columns=['DRR'], axis=1, inplace=True)\n",
    "\n",
    "#### 날씨 데이터 추가 후 주석 제거할 것.\n",
    "# 날씨 관련 안쓰는 feature 삭제\n",
    "# df.drop(columns=['rain', 'weatherCode'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ATT (actual time data)가 missing된 레코드 삭제 \n",
    "df = df[pd.notnull(df['ATT'])]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ARP와 ODP가 같은 데이터를  wrong data로 간주하여 삭제\n",
    "df.drop(df[df['ARP'] == df['ODP']].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ARP 경로 파생변수 생성\n",
    "df['ARPODP'] = df['ARP'] + '_' + df['ODP']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "\n",
    "df['Diff'] = (pd.to_datetime(df['ATT'],format= '%H:%M') - pd.to_datetime(df['STT'],format= '%H:%M')).dt.seconds.astype('int64')\n",
    "\n",
    "#### STT와 ATT 격차 큰 순대로 정렬\n",
    "df = df.sort_values(by=['Diff'], ascending=False)\n",
    "\n",
    "########################################################################출발\n",
    "# 딜레이가 최대 5시간이라고 가정했을 때, --> 즉, 2시간 초과한 딜레이는 wrong값이라 가정\n",
    "max_delay_hour = 5\n",
    "max_delay = max_delay_hour * 3600 # seconds\n",
    "\n",
    "#### 출발비행기의 경우, 조금이라도 출발이 빠른 건 wrong data라 판단.\n",
    "#### 7200보다 큰 값을 가지는 Diff 데이터 wrong 값 처리\n",
    "df = df[((df['Diff'] <= max_delay) & (df['AOD']=='D')) | (df['AOD']=='A')]\n",
    "\n",
    "df.head(100)\n",
    "\n",
    "########################################################################도착\n",
    "#### 이정도는 늦게 도착해도 O\n",
    "#### 2시간은 예상보다 늦게도착할 수 있다. 그 이상은 말이안된다\n",
    "max_delay_hour_arr = 5\n",
    "max_delay_arr = max_delay_hour_arr * 3600 # seconds\n",
    "\n",
    "#### 몇분 일찍도착해도 O\n",
    "#### 30분은 예상보다 빨리도착할 수 있음. 그거보다 빨리도착하는 건 말이 안됨\n",
    "min_delay = 30*60\n",
    "min_delay = 86400 - min_delay  # 86400(24시간)보다 위인거만 살려놓기\n",
    "df = df[(df['AOD']=='D') |((df['Diff'] <= max_delay_arr) & (df['AOD']=='A')) | ((df['AOD']=='A')& (df['Diff'] >= min_delay )) ]\n",
    "df.loc[df['Diff'] >=min_delay, 'Diff'] = df.loc[df['Diff'] >=min_delay, 'Diff']  - 86400\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Check the numerical data\n",
    "numerical_feature = [col for col in df.columns if df[col].dtypes == 'int64']\n",
    "print(numerical_feature)\n",
    "\n",
    "def dist_box(df, feature_list):\n",
    "    for col in feature_list:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        sns.distplot(df.loc[df[col].notnull(), col])\n",
    "        plt.title(col)\n",
    "        plt.show()\n",
    "        \n",
    "        df[col].plot(kind='box', color='red')\n",
    "        plt.show()\n",
    "\n",
    "\"\"\"\n",
    "print('*'*50)\n",
    "print('All')\n",
    "dist_box(df, numerical_feature)\n",
    "print('*'*50)\n",
    "print('Arrive')\n",
    "dist_box(df[df['AOD'] == 'A'], numerical_feature)\n",
    "print('*'*50)\n",
    "print('Departure')\n",
    "dist_box(df[df['AOD'] == 'D'], numerical_feature)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Categorical data --> one hot encoding\n",
    "\n",
    "def one_hot_dummies(df, *args):\n",
    "    for col in args:\n",
    "        one_hot_col = pd.get_dummies(df[col])\n",
    "        df = df.drop([col], axis = 1)\n",
    "        \n",
    "        try:\n",
    "            df = df.join(one_hot_col)\n",
    "        except:\n",
    "            one_hot_col.rename(columns={'ARP1':'ARP1_','ARP2':'ARP2_','ARP3':'ARP3_','ARP4':'ARP4_','ARP5':'ARP5_',\n",
    "                                        'ARP14':'ARP14_','ARP12':'ARP12_','ARP10':'ARP10_','ARP8':'ARP8_','ARP6':'ARP6_',\n",
    "                                        'ARP15':'ARP15_','ARP13':'ARP13_','ARP11':'ARP11_','ARP9':'ARP9_','ARP7':'ARP7_'},\n",
    "                               inplace=True)\n",
    "            df = df.join(one_hot_col)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = one_hot_dummies(df, 'ARP', 'ODP', 'FLO', 'ARPODP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[['Month', 'STT']] = scaler.fit_transform(df[['Month', 'STT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Target 레이블링\n",
    "\n",
    "from sklearn import preprocessing\n",
    "#### DLY도 1과 0으로 데이터 처리\n",
    "le = preprocessing.LabelEncoder()\n",
    "df[['DLY']] = le.fit_transform(df[['DLY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 도착, 출발 데이터 분리\n",
    "df_A = df[df['AOD']=='A']\n",
    "df_D = df[df['AOD']=='D']\n",
    "\n",
    "#### AOD column삭제 \n",
    "df_A = df_A.drop(['AOD'],axis = 1)\n",
    "df_D = df_D.drop(['AOD'],axis = 1)\n",
    "\n",
    "df_A.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTestSet(df):\n",
    "    X = df.drop(['DLY'], axis = 1)\n",
    "    y = df['DLY']\n",
    "        \n",
    "    X_tr, X_t, y_tr, y_t = train_test_split(X,y, test_size= 0.3, random_state = 42)\n",
    "    \n",
    "    print(\"X_train set--------------------\")\n",
    "    print(\"Shape:\",X_tr.shape)\n",
    "    print(\"Target:\")\n",
    "    print(y_tr.value_counts())\n",
    "    print()\n",
    "      \n",
    "    print(\"X_test set info-----------------\")\n",
    "    print(\"Shape:\",X_t.shape)\n",
    "    print(\"Target:\")\n",
    "    print(y_t.value_counts())\n",
    "    print()\n",
    "\n",
    "    return [X_tr, X_t, y_tr, y_t]\n",
    "\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = makeTestSet(df_A)\n",
    "X_train_D, X_test_D, y_train_D, y_test_D = makeTestSet(df_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------변수 중요도 확인하고 상위 OO개 남기기 -------------------\n",
    "\n",
    "def feature_importance(X_train, y_train, X_test, y_test):\n",
    "        \n",
    "    #### Skew Data처리할거면 주석 해제하기!!\n",
    "    #X_train, y_train = imbalance(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    log_rg = LogisticRegression().fit(X_train, y_train)\n",
    "    cross_val_score(log_rg, X_train, y_train, cv=5)\n",
    "    log_rg.score(X_test, y_test)\n",
    "    print(classification_report(y_test, log_rg.predict(X_test)))\n",
    "\n",
    "    # X column 개수 출력\n",
    "    #print(len(X.columns)) \n",
    "\n",
    "    # 변수 중요도 \n",
    "    fi = pd.DataFrame(zip(X_train.columns.values, abs(log_rg.coef_.ravel())))\n",
    "    fi.columns = ['feature', 'coef']\n",
    "    fi.sort_values(\"coef\", ascending=False, inplace=True)\n",
    "    fi = fi.reset_index().drop(['index'], axis=1)\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(fi)\n",
    "\n",
    "    for index, val in enumerate(fi.iloc[:, 1]):\n",
    "        if val < 0.1:\n",
    "            X_train.drop([fi.iloc[index, 0]], axis = 1, inplace = True)\n",
    "            X_test.drop([fi.iloc[index, 0]], axis = 1, inplace = True)   \n",
    "    return\n",
    "\n",
    "feature_importance(X_train_A, y_train_A, X_test_A, y_test_A)\n",
    "feature_importance(X_train_D, y_train_D, X_test_D, y_test_D)\n",
    "print(len(X_train_A.columns))\n",
    "print(len(X_test_A.columns))\n",
    "print(len(X_train_D.columns))\n",
    "print(len(X_test_D.columns))\n",
    "\n",
    "#--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalance (X_train, y_train):\n",
    "\n",
    "    # 모델설정\n",
    "    sm = SMOTE(ratio='auto', kind='regular')\n",
    "\n",
    "    # train데이터를 넣어 복제함\n",
    "    X_resampled, y_resampled = sm.fit_sample(X_train,list(y_train))\n",
    "\n",
    "    print('After OverSampling, the shape of train_X: {}'.format(X_resampled.shape))\n",
    "    print('After OverSampling, the shape of train_y: {} \\n'.format(X_resampled.shape))\n",
    "\n",
    "    print(\"After OverSampling, counts of label '1': {}\".format(sum(y_resampled==1)))\n",
    "    print(\"After OverSampling, counts of label '0': {}\".format(sum(y_resampled==0)))\n",
    "    \n",
    "    return [X_resampled, y_resampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve그리기\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \n",
    "    \n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_heatmap(y_true, y_pred):\n",
    "    data = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.set(font_scale=1.4)#for label size\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel (X_train, y_train, X_test, y_test, base = True):\n",
    "    \n",
    "    #X_train, y_train = underSampling(X_train, y_train)\n",
    "    \n",
    "     ## Skew Data처리할거면 주석 풀기!!\n",
    "    X_train, y_train = imbalance(X_train, y_train)\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    if base ==True:\n",
    "        models.append(('RF', RandomForestClassifier(max_depth=6, n_estimators=1000, random_state=0, criterion='entropy')))\n",
    "    else:\n",
    "#         models.append(('LR', LogisticRegression()))\n",
    "#         models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "#         models.append(('KNN', KNeighborsClassifier()))\n",
    "#         models.append(('CART', DecisionTreeClassifier()))\n",
    "#         models.append(('NB', GaussianNB()))\n",
    "        models.append(('RF', RandomForestClassifier(max_depth=4, n_estimators=100, random_state=0)))\n",
    "#         models.append(('SVM', SVC(gamma='auto')))\n",
    "#         models.append(('XGB', XGBClassifier()))\n",
    "\n",
    "    \n",
    "    # 평가\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = 'recall'\n",
    "\n",
    "    seed = 7\n",
    "    for name, model in models:\n",
    "        # K-Fold\n",
    "#         kfold = KFold(n_splits=10, random_state=seed)\n",
    "#         cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "#         results.append(cv_results)\n",
    "#         names.append(name)\n",
    "#         msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#         print(msg)\n",
    "\n",
    "        # Hold out \n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = pd.Series(model.predict(X_test))\n",
    "\n",
    "        # Resets index to compare original test data with predicted data\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "        y_predict = y_predict.reset_index(drop=True)\n",
    "\n",
    "#         plt.figure(figsize=(15, 5))\n",
    "#         plt.scatter(range(y_test.shape[0]), y_test, c='gray')\n",
    "#         plt.scatter(range(y_predict.shape[0]), y_predict , c='r')\n",
    "#         diff = abs(y_test - y_predict)\n",
    "#         plt.bar(range(diff.shape[0]), diff, color='gray')\n",
    "#         plt.title('Result - Original comparsion')\n",
    "#         plt.legend(['Original', 'Predict'])\n",
    "#         plt.show()\n",
    "\n",
    "        print(model.score(X_test, y_test))\n",
    "        print('-' * 50)\n",
    "        \n",
    "        #--------ROC Curve-----------------\n",
    "        probs = model.predict_proba(X_test)\n",
    "        probs = probs[:, 1]\n",
    "        auc = roc_auc_score(y_test, probs)\n",
    "        print('AUC: %.2f' % auc)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "        plot_roc_curve(fpr, tpr)\n",
    "        #-----------------------------------\n",
    "        \n",
    "        #-------- Confusion matrix heatmap -----------------\n",
    "        confusion_matrix_heatmap(y_test, y_predict)\n",
    "        print(classification_report(y_test, y_predict))\n",
    "        #-----------------------------------\n",
    "        \n",
    "             \n",
    "#      # boxplot algorithm comparison\n",
    "#     fig = plt.figure(figsize=(11,6))\n",
    "#     fig.suptitle('Algorithm Comparison')\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     plt.boxplot(results)\n",
    "#     ax.set_xticklabels(names)\n",
    "#     plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True면 base algorithm만 실행하겠다 (base algorithm : Random Forest)\n",
    "# False면 모든 알고리즘을 실행하겠다.\n",
    "runModel (X_train_D,y_train_D, X_test_D, y_test_D, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True면 base algorithm만 실행하겠다 (base algorithm : Random Forest)\n",
    "# False면 모든 알고리즘을 실행하겠다.\n",
    "runModel (X_train_A,y_train_A, X_test_A, y_test_A, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDT_YY</th>\n",
       "      <th>SDT_MM</th>\n",
       "      <th>SDT_DD</th>\n",
       "      <th>SDT_DY</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ODP</th>\n",
       "      <th>FLO</th>\n",
       "      <th>FLT</th>\n",
       "      <th>AOD</th>\n",
       "      <th>STT</th>\n",
       "      <th>DLY</th>\n",
       "      <th>DLY_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>L</td>\n",
       "      <td>L1702</td>\n",
       "      <td>A</td>\n",
       "      <td>9:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>L</td>\n",
       "      <td>L1702</td>\n",
       "      <td>D</td>\n",
       "      <td>7:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>`</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>L</td>\n",
       "      <td>L1720</td>\n",
       "      <td>A</td>\n",
       "      <td>14:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>L</td>\n",
       "      <td>L1720</td>\n",
       "      <td>D</td>\n",
       "      <td>13:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP4</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>L</td>\n",
       "      <td>L1808</td>\n",
       "      <td>A</td>\n",
       "      <td>20:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDT_YY  SDT_MM  SDT_DD SDT_DY   ARP   ODP FLO    FLT AOD    STT  DLY  \\\n",
       "0    2019       9      16      월  ARP1  ARP3   L  L1702   A   9:05  NaN   \n",
       "1    2019       9      16      월  ARP3  ARP1   L  L1702   D   7:55  NaN   \n",
       "2    2019       9      16      월     `  ARP3   L  L1720   A  14:40  NaN   \n",
       "3    2019       9      16      월  ARP3  ARP1   L  L1720   D  13:30  NaN   \n",
       "4    2019       9      16      월  ARP4  ARP3   L  L1808   A  20:10  NaN   \n",
       "\n",
       "   DLY_RATE  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#우리가 예측해야 할 데이터\n",
    "dly = pd.read_csv('AFSNT_DLY.CSV', encoding=\"cp949\")\n",
    "dly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요없는 column 제거\n",
    "dly.drop(columns=['FLT', 'DLY', 'DLY_RATE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDT_YY</th>\n",
       "      <th>SDT_MM</th>\n",
       "      <th>SDT_DD</th>\n",
       "      <th>SDT_DY</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ODP</th>\n",
       "      <th>FLO</th>\n",
       "      <th>AOD</th>\n",
       "      <th>STT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>9:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>7:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>`</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>14:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>13:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP4</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>20:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDT_YY  SDT_MM  SDT_DD SDT_DY   ARP   ODP FLO AOD    STT\n",
       "0    2019       9      16      월  ARP1  ARP3   L   A   9:05\n",
       "1    2019       9      16      월  ARP3  ARP1   L   D   7:55\n",
       "2    2019       9      16      월     `  ARP3   L   A  14:40\n",
       "3    2019       9      16      월  ARP3  ARP1   L   D  13:30\n",
       "4    2019       9      16      월  ARP4  ARP3   L   A  20:10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수\n",
    "dly['ARPODP'] = dly['ARP'] + '_' + dly['ODP']\n",
    "# 분 삭제\n",
    "dly['hour'] = pd.to_datetime(dly['STT'],format= '%H:%M').dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "#날씨데이터 json 읽어오는 함수\n",
    "\n",
    "#나중에 9월 1일을 9월 16일로 바꾼 후 실행..\n",
    "#(읽어오는거 확인용으로 9월 1일 부터...)\n",
    "def readJSON(area):\n",
    "    \n",
    "    request = urllib.request.urlopen('https://api.aerisapi.com/forecasts/'+area+',korea?from=09/16/2019&format=json&filter=1hr&limit=999&client_id=gHOhinKWCL1fwDUpI1Ec7&client_secret=TRamBTyXpORXcmDKVqc2S4i4mnCjVxxHMt6cllui')\n",
    "    response = request.read()\n",
    "    data= json.loads(response)\n",
    "\n",
    "\n",
    "    if data['success']:\n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        print(\"An error occurred: %s\" % (data['error']['description']))\n",
    "        return \"\"\n",
    "        request.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#날씨 csv 저장\n",
    "def storeWeather():\n",
    "    futureweather=pd.DataFrame(columns=['SDT_YY', 'SDT_MM', 'SDT_DD','hour','ARP','temp', 'hum', 'dew', 'windSpeed','hpa'])\n",
    "\n",
    "    for i in range(15):\n",
    "        area=[\"seoul\",\"busan\",\"jeju\",\"daegu\",\"ulsan\",\"cheongju\",\"muan\",\"gwangju\",\"yeosu\"\n",
    "              ,\"yangyang\",\"pohang\",\"sacheon\",\"gunsan\",\"wonju\",\"incheon\"]\n",
    "        d=readJSON(area[i])\n",
    "        response=d['response'][0]\n",
    "        data=response['periods']\n",
    "    \n",
    "    \n",
    "        for j in range(len(data)):\n",
    "            temp=data[j]\n",
    "            date=dateutil.parser.parse(temp['dateTimeISO'])\n",
    "            temp2=pd.Series([date.year,date.month,date.day,date.hour,\"ARP\"+str(i+1),temp['tempC'],\n",
    "                         temp['humidity'],temp['dewpointC'],temp['windGustKTS'],temp['pressureMB']],\n",
    "                        index=['SDT_YY', 'SDT_MM', 'SDT_DD','hour','ARP','temp', 'hum', 'dew', 'windSpeed','hpa'])\n",
    "        \n",
    "            futureweather=futureweather.append(temp2,ignore_index=True)\n",
    "    \n",
    "    #fog 모델하고의 단위 맞추는 작업\n",
    "    futureweather['windSpeed']=futureweather['windSpeed'].astype(\"float\")*1852/3600\n",
    "    \n",
    "    futureweather.to_csv(\"newWeather.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일 저장하고 싶을때만 실행..\n",
    "storeWeather() \n",
    "\n",
    "# 날씨데이터 합치기---------------------\n",
    "\n",
    "we=pd.read_csv('newWeather.csv', encoding=\"cp949\")\n",
    "\n",
    "final= pd.merge(we, dly, on=['SDT_YY', 'SDT_MM', 'SDT_DD', 'ARP','hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDT_YY</th>\n",
       "      <th>SDT_MM</th>\n",
       "      <th>SDT_DD</th>\n",
       "      <th>hour</th>\n",
       "      <th>ARP</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>dew</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>hpa</th>\n",
       "      <th>SDT_DY</th>\n",
       "      <th>ODP</th>\n",
       "      <th>FLO</th>\n",
       "      <th>AOD</th>\n",
       "      <th>STT</th>\n",
       "      <th>ARPODP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>2.572222</td>\n",
       "      <td>1017</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>L</td>\n",
       "      <td>D</td>\n",
       "      <td>6:40</td>\n",
       "      <td>ARP1_ARP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>2.572222</td>\n",
       "      <td>1017</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP12</td>\n",
       "      <td>J</td>\n",
       "      <td>D</td>\n",
       "      <td>6:50</td>\n",
       "      <td>ARP1_ARP12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>2.572222</td>\n",
       "      <td>1017</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>6:10</td>\n",
       "      <td>ARP1_ARP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>2.572222</td>\n",
       "      <td>1017</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>6:15</td>\n",
       "      <td>ARP1_ARP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>22</td>\n",
       "      <td>2.572222</td>\n",
       "      <td>1017</td>\n",
       "      <td>월</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>J</td>\n",
       "      <td>D</td>\n",
       "      <td>6:20</td>\n",
       "      <td>ARP1_ARP3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDT_YY  SDT_MM  SDT_DD  hour   ARP  temp  hum  dew  windSpeed   hpa SDT_DY  \\\n",
       "0    2019       9      16     6  ARP1    23   94   22   2.572222  1017      월   \n",
       "1    2019       9      16     6  ARP1    23   94   22   2.572222  1017      월   \n",
       "2    2019       9      16     6  ARP1    23   94   22   2.572222  1017      월   \n",
       "3    2019       9      16     6  ARP1    23   94   22   2.572222  1017      월   \n",
       "4    2019       9      16     6  ARP1    23   94   22   2.572222  1017      월   \n",
       "\n",
       "     ODP FLO AOD   STT      ARPODP  \n",
       "0   ARP3   L   D  6:40   ARP1_ARP3  \n",
       "1  ARP12   J   D  6:50  ARP1_ARP12  \n",
       "2   ARP3   F   D  6:10   ARP1_ARP3  \n",
       "3   ARP3   F   D  6:15   ARP1_ARP3  \n",
       "4   ARP3   J   D  6:20   ARP1_ARP3  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictFiveDays(df2):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "    for i in range(6):\n",
    "        update=[]\n",
    "        for j in range(24):\n",
    "            newTemp=0.0\n",
    "            newHum=0.0\n",
    "            newDew=0.0\n",
    "            newWindSpeed=0.0\n",
    "            newHpa=0.0\n",
    "            newDew=0.0\n",
    "            for k in range(5):\n",
    "                newTemp += df2[(df2['SDT_DD']==25+i-k+1) & (df2['hour']==j)]['temp']\n",
    "                newHum += df2[(df2['SDT_DD']==25+i-k+1) & (df2['hour']==j)]['hum']\n",
    "                newDew += df2[(df2['SDT_DD']==25+i-k+1) & (df2['hour']==j)]['dew']\n",
    "                newWindSpeed += df2[(df2['SDT_DD']==25+i-k+1) & (df2['hour']==j)]['windSpeed']\n",
    "                newHpa += df2[(df2['SDT_DD']==25+i-k+1) & (df2['hour']==j)]['hpa']\n",
    "                #newDew += df[(df['SDT_DD']==25+i-k+1) & (df['STT']==j)]['dew']\n",
    "#            print(df[(df['SDT_DD']==25+i-k) & (df['STT']==j)]['temp'])\n",
    "            df2[(df2['SDT_DD']==25+i) & (df2['hour']==j)]['temp']= newTemp / 5\n",
    "            df2[(df2['SDT_DD']==25+i) & (df2['hour']==j)]['hum']= newHum / 5\n",
    "            df2[(df2['SDT_DD']==25+i) & (df2['hour']==j)]['dew']= newDew / 5\n",
    "            df2[(df2['SDT_DD']==25+i) & (df2['hour']==j)]['windSpeed']= newWindSpeed / 5\n",
    "        \n",
    "    print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SDT_YY  SDT_MM  SDT_DD  hour    ARP  temp  hum  dew  windSpeed   hpa  \\\n",
      "0       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "1       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "2       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "3       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "4       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "5       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "6       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "7       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "8       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "9       2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "10      2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "11      2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "12      2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "13      2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "14      2019       9      16     6   ARP1    23   94   22   2.572222  1017   \n",
      "15      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "16      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "17      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "18      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "19      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "20      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "21      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "22      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "23      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "24      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "25      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "26      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "27      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "28      2019       9      16     7   ARP1    23   93   22   3.086667  1017   \n",
      "29      2019       9      16     8   ARP1    24   92   22   3.086667  1017   \n",
      "...      ...     ...     ...   ...    ...   ...  ...  ...        ...   ...   \n",
      "2338    2019       9      16     8  ARP15    24   92   22   3.601111  1017   \n",
      "2339    2019       9      16     8  ARP15    24   92   22   3.601111  1017   \n",
      "2340    2019       9      16    11  ARP15    25   89   23   4.115556  1016   \n",
      "2341    2019       9      16    14  ARP15    26   85   23   4.630000  1016   \n",
      "2342    2019       9      16    17  ARP15    25   88   23   3.601111  1016   \n",
      "2343    2019       9      16    17  ARP15    25   88   23   3.601111  1016   \n",
      "2344    2019       9      16    17  ARP15    25   88   23   3.601111  1016   \n",
      "2345    2019       9      16    18  ARP15    24   90   23   3.601111  1016   \n",
      "2346    2019       9      16    19  ARP15    24   92   22   3.086667  1016   \n",
      "2347    2019       9      16    19  ARP15    24   92   22   3.086667  1016   \n",
      "2348    2019       9      16    19  ARP15    24   92   22   3.086667  1016   \n",
      "2349    2019       9      17     6  ARP15    23   94   22   2.572222  1017   \n",
      "2350    2019       9      17     8  ARP15    23   93   22   3.086667  1018   \n",
      "2351    2019       9      17     8  ARP15    23   93   22   3.086667  1018   \n",
      "2352    2019       9      17     8  ARP15    23   93   22   3.086667  1018   \n",
      "2353    2019       9      17     8  ARP15    23   93   22   3.086667  1018   \n",
      "2354    2019       9      17     9  ARP15    24   92   22   3.086667  1018   \n",
      "2355    2019       9      17    11  ARP15    25   86   22   3.086667  1017   \n",
      "2356    2019       9      17    17  ARP15    25   81   21   2.572222  1017   \n",
      "2357    2019       9      17    17  ARP15    25   81   21   2.572222  1017   \n",
      "2358    2019       9      17    18  ARP15    24   84   21   2.057778  1017   \n",
      "2359    2019       9      17    19  ARP15    23   88   21   2.057778  1018   \n",
      "2360    2019       9      17    19  ARP15    23   88   21   2.057778  1018   \n",
      "2361    2019       9      17    19  ARP15    23   88   21   2.057778  1018   \n",
      "2362    2019       9      17    19  ARP15    23   88   21   2.057778  1018   \n",
      "2363    2019       9      18     6  ARP15    22   91   20   1.543333  1017   \n",
      "2364    2019       9      18     8  ARP15    23   87   20   1.543333  1017   \n",
      "2365    2019       9      18     8  ARP15    23   87   20   1.543333  1017   \n",
      "2366    2019       9      18     8  ARP15    23   87   20   1.543333  1017   \n",
      "2367    2019       9      18     8  ARP15    23   87   20   1.543333  1017   \n",
      "\n",
      "     SDT_DY    ODP FLO AOD    STT      ARPODP  \n",
      "0         월   ARP3   L   D   6:40   ARP1_ARP3  \n",
      "1         월  ARP12   J   D   6:50  ARP1_ARP12  \n",
      "2         월   ARP3   F   D   6:10   ARP1_ARP3  \n",
      "3         월   ARP3   F   D   6:15   ARP1_ARP3  \n",
      "4         월   ARP3   J   D   6:20   ARP1_ARP3  \n",
      "5         월   ARP3   A   D   6:05   ARP1_ARP3  \n",
      "6         월   ARP3   H   D   6:15   ARP1_ARP3  \n",
      "7         월   ARP3   F   D   6:50   ARP1_ARP3  \n",
      "8         월   ARP3   A   D   6:25   ARP1_ARP3  \n",
      "9         월   ARP3   H   D   6:25   ARP1_ARP3  \n",
      "10        월   ARP3   B   D   6:55   ARP1_ARP3  \n",
      "11        월   ARP3   A   D   6:40   ARP1_ARP3  \n",
      "12        월   ARP3   I   D   6:05   ARP1_ARP3  \n",
      "13        월   ARP3   I   D   6:10   ARP1_ARP3  \n",
      "14        월   ARP4   B   D   6:50   ARP1_ARP4  \n",
      "15        월   ARP3   L   D   7:00   ARP1_ARP3  \n",
      "16        월   ARP5   B   D   7:10   ARP1_ARP5  \n",
      "17        월   ARP2   B   A   7:55   ARP1_ARP2  \n",
      "18        월   ARP2   B   D   7:30   ARP1_ARP2  \n",
      "19        월   ARP2   J   D   7:00   ARP1_ARP2  \n",
      "20        월   ARP3   A   D   7:55   ARP1_ARP3  \n",
      "21        월   ARP3   A   A   7:40   ARP1_ARP3  \n",
      "22        월   ARP3   A   A   7:50   ARP1_ARP3  \n",
      "23        월   ARP3   J   D   7:20   ARP1_ARP3  \n",
      "24        월   ARP3   H   D   7:00   ARP1_ARP3  \n",
      "25        월   ARP3   B   D   7:20   ARP1_ARP3  \n",
      "26        월   ARP3   H   D   7:40   ARP1_ARP3  \n",
      "27        월   ARP3   A   D   7:25   ARP1_ARP3  \n",
      "28        월   ARP3   I   D   7:05   ARP1_ARP3  \n",
      "29        월   ARP3   L   D   8:15   ARP1_ARP3  \n",
      "...     ...    ...  ..  ..    ...         ...  \n",
      "2338      월   ARP2   A   A   8:00  ARP15_ARP2  \n",
      "2339      월   ARP4   J   A   8:05  ARP15_ARP4  \n",
      "2340      월   ARP2   J   A  11:55  ARP15_ARP2  \n",
      "2341      월   ARP2   J   A  14:35  ARP15_ARP2  \n",
      "2342      월   ARP2   J   A  17:40  ARP15_ARP2  \n",
      "2343      월   ARP2   A   A  17:00  ARP15_ARP2  \n",
      "2344      월   ARP2   J   D  17:15  ARP15_ARP2  \n",
      "2345      월   ARP2   J   D  18:25  ARP15_ARP2  \n",
      "2346      월   ARP2   A   D  19:20  ARP15_ARP2  \n",
      "2347      월   ARP2   J   D  19:35  ARP15_ARP2  \n",
      "2348      월   ARP4   J   D  19:35  ARP15_ARP4  \n",
      "2349      화   ARP2   A   D   6:30  ARP15_ARP2  \n",
      "2350      화   ARP2   J   D   8:25  ARP15_ARP2  \n",
      "2351      화   ARP2   J   A   8:10  ARP15_ARP2  \n",
      "2352      화   ARP2   A   A   8:00  ARP15_ARP2  \n",
      "2353      화   ARP4   J   A   8:15  ARP15_ARP4  \n",
      "2354      화   ARP2   J   A   9:10  ARP15_ARP2  \n",
      "2355      화   ARP2   J   A  11:55  ARP15_ARP2  \n",
      "2356      화   ARP2   J   A  17:40  ARP15_ARP2  \n",
      "2357      화   ARP2   J   D  17:15  ARP15_ARP2  \n",
      "2358      화   ARP2   J   D  18:25  ARP15_ARP2  \n",
      "2359      화   ARP2   A   A  19:30  ARP15_ARP2  \n",
      "2360      화   ARP2   A   D  19:20  ARP15_ARP2  \n",
      "2361      화   ARP2   J   D  19:35  ARP15_ARP2  \n",
      "2362      화   ARP4   J   D  19:35  ARP15_ARP4  \n",
      "2363      수   ARP2   A   D   6:30  ARP15_ARP2  \n",
      "2364      수   ARP2   J   D   8:25  ARP15_ARP2  \n",
      "2365      수   ARP2   J   A   8:10  ARP15_ARP2  \n",
      "2366      수   ARP2   A   A   8:00  ARP15_ARP2  \n",
      "2367      수   ARP4   J   A   8:15  ARP15_ARP4  \n",
      "\n",
      "[2368 rows x 16 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d89a985d2cb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# YY랑 DD삭제\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfinal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SDT_YY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SDT_DD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "final=predictFiveDays(final)\n",
    "\n",
    "# YY랑 DD삭제\n",
    "final.drop(columns=['SDT_YY', 'SDT_DD'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = one_hot_dummies(final, 'SDT_MM', 'SDT_DY', 'ARP', 'ODP', 'FLO',  'STT','ARPODP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def fogModel(df):\n",
    "    # 날씨 missing 값들은 0으로 대체\n",
    "    df.fillna(0, inplace = True)\n",
    "    \n",
    "    # 모델에서 쓰인 Scaling기법 적용\n",
    "    scaler = RobustScaler()\n",
    "    df[['hum', 'dew','temp','windSpeed']] = scaler.fit_transform(df[['hum', 'dew','temp','windSpeed']])\n",
    "    \n",
    "    # 저장된 모델 불러오기\n",
    "    clf_from_joblib = joblib.load('fogmodel.pkl') \n",
    "\n",
    "    # 지연 율 저장\n",
    "    fog_prob = clf_from_joblib.predict_proba(df)\n",
    "    \n",
    "\n",
    "    fog_column = []\n",
    "    # dly_rate에 지연율 저장\n",
    "    for i in fog_prob:\n",
    "        fog_column.append(i[1])\n",
    "        \n",
    "    \n",
    "    return fog_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df에서 fog관련 column만 함수에 넘김\n",
    "fog = final[[\"temp\",\"hum\",\"dew\",\"windSpeed\"]]\n",
    "\n",
    "fog_column = fogModel(fog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 안개 column 추가\n",
    "final['fog'] = fog_column\n",
    "\n",
    "# 안개 관련 column 제거\n",
    "final.drop(columns=['hum', 'dew','temp','windSpeed'], axis=1, inplace=True)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도착, 출발 데이터 분리\n",
    "final_A = final[final['AOD']=='A']\n",
    "final_D = final[final['AOD']=='D']\n",
    "\n",
    "# AOD column삭제 \n",
    "final_A = final_A.drop(['AOD'],axis = 1)\n",
    "final_D = final_D.drop(['AOD'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 아직 저장된 모델이 없음\n",
    "\n",
    "# df_A 모델 -----------------------------------------------\n",
    "\n",
    "# df_A 모델 불러오기\n",
    "predict_dealy_A_joblib = joblib.load('predict_delay_A.pkl') \n",
    "\n",
    "# DLY 저장하기\n",
    "dly_A = predict_dealy_A_joblib.predict(final_A)\n",
    "\n",
    "# DLY_RATE 저장하기\n",
    "dly_A_prob = predict_dealy_A_joblib.predict_proba(final_A)\n",
    "\n",
    "dly_rate_A = []\n",
    "\n",
    "# dly_rate에 지연율 저장\n",
    "for i in dly_A_prob:\n",
    "    dly_rate_A.append(i[1])\n",
    "    \n",
    "# DateFrame에 DLY, DLY_RATE추가\n",
    "final.loc[final['AOD']=='A','DLY'] = dly_A\n",
    "final.loc[final['AOD']=='A','DLY_RATE'] = dly_rate_A\n",
    "\n",
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_D 모델 -----------------------------------------------\n",
    "\n",
    "# df_D 모델 불러오기\n",
    "predict_dealy_D_joblib = joblib.load('predict_delay_D.pkl') \n",
    "\n",
    "# DLY 저장하기\n",
    "dly_D = predict_dealy_D_joblib.predict(final_D)\n",
    "\n",
    "# DLY_RATE 저장하기\n",
    "dly_A_prob = predict_dealy_A_joblib.predict_proba(final_D)\n",
    "\n",
    "dly_rate_D = []\n",
    "\n",
    "# dly_rate에 지연율 저장\n",
    "for i in dly_D_prob:\n",
    "    dly_rate_D.append(i[1])\n",
    "    \n",
    "# DateFrame에 DLY, DLY_RATE추가\n",
    "final.loc[final['AOD']=='D','DLY'] = dly_D\n",
    "final.loc[final['AOD']=='D','DLY_RATE'] = dly_rate_D\n",
    "\n",
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨을 1,0에서 -> Y,N으로 \n",
    "final.loc[final['DLY']==1,'DLY'] = 'Y'\n",
    "final.loc[final['DLY']==0,'DLY'] = 'N'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
