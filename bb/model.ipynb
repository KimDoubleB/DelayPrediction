{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n전체 출력문\\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\\n    print(df)\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# read 데이터\n",
    "df = pd.read_csv('weatherFinal2.CSV', encoding=\"cp949\")\n",
    "df.head()\n",
    "'''\n",
    "전체 출력문\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['rain' 'weatherCode'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e8b98b206716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m############# 날씨 데이터 추가 후 주석 제거할 것.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# 날씨 관련 안쓰는 feature 삭제\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weatherCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['rain' 'weatherCode'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = df[df.IRR != \"Y\"] # 부정기 없애기 \n",
    "df = df[df.CNL != \"Y\"]\n",
    "\n",
    "# 비행기 취소와 관련된 Column 삭제\n",
    "df.drop(columns=['CNL', 'CNR'], axis=1, inplace=True)\n",
    "\n",
    "# 사용되지 않을 것 같은 데이터 일단 삭제\n",
    "df.drop(columns=['REG', 'IRR'], axis=1, inplace=True)\n",
    "\n",
    "# 딜레이 이유 (나중에 쓰일 듯)\n",
    "df.drop(columns=['DRR'], axis=1, inplace=True)\n",
    "\n",
    "############# 날씨 데이터 추가 후 주석 제거할 것.\n",
    "# 날씨 관련 안쓰는 feature 삭제\n",
    "df.drop(columns=['rain', 'weatherCode'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT (actual time data)가 널 값인 레코드 삭제\n",
    "df = df[pd.notnull(df['ATT'])]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['SDT_YY'] = df['SDT_YY'].astype('object')\n",
    "# df['SDT_MM'] = df['SDT_MM'].astype('object')\n",
    "# df['SDT_DD'] = df['SDT_DD'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ARP와 ODP가 같은 데이터 --> Wrong data => 삭제\n",
    "df.drop(df[df['ARP'] == df['ODP']].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- fog 모델 돌리기 --------------\n",
    "\n",
    "## INPUT : 'temp', 'hum', 'dew', 'windSpeed' 4가지 Column의 DataFrame\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def fogPreProcessing (df):\n",
    "    # 비어있는 값 0으로 대체\n",
    "    #print(df.isnull().sum())\n",
    "    df.fillna(0, inplace = True)\n",
    "  \n",
    "    # MinMaxScaling\n",
    "    scaler = MinMaxScaler()\n",
    "    df[['hum', 'dew','temp','windSpeed']] = scaler.fit_transform(df[['hum', 'dew','temp','windSpeed']])\n",
    "  \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fog = df[[\"temp\",\"hum\",\"dew\",\"windSpeed\"]]\n",
    "\n",
    "fog = fogPreProcessing(fog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# 저장된 모델 불러오기\n",
    "clf_from_joblib = joblib.load('fogmodel.pkl') \n",
    "\n",
    "# 저장된 모델로 예측하기\n",
    "#clf_from_joblib.predict(fog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측할 때 확률로가져오기!\n",
    "result = clf_from_joblib.predict_proba(fog)\n",
    "\n",
    "fog_column = []\n",
    "\n",
    "# fog_column에 확률값 저장\n",
    "for i in result:\n",
    "    fog_column.append(i[1])\n",
    "    \n",
    "print(\"fog_column :\",len(fog_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fog'] = fog_column\n",
    "\n",
    "df.drop(columns=['hum', 'dew','temp','windSpeed'], axis=1, inplace=True)\n",
    "df.head()\n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------연결지연 시도--------------------------\n",
    "df123 = df.copy()\n",
    "df123['AIR'] = (df123['FLT']).str[1:4]\n",
    "df123.loc[df123['AOD'] == 'D', 'TEMP'] = df123['ODP'] + '-' + df123['AOD'] + '-' + df123['ATT']\n",
    "df123.loc[df123['AOD'] == 'A', 'TEMP'] = df123['ARP'] + '-' + df123['AOD'] + '-' + df123['ATT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df123['TEMP2'] = pd.to_datetime(df['ATT'],format= '%H:%M')\n",
    "# df123 = df123.sort_values(['AIR','FLO','DAY','TEMP2']).reset_index(drop=True)\n",
    "# df123.drop(['SDT_DY','STT','ATT','ARP','ODP','FLO'], axis = 1, inplace=True)\n",
    "# df123['ABNORMAL'] = False\n",
    "\n",
    "# df234 = df123.iloc[0:0]\n",
    "\n",
    "# # with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "# #     print(df123.head(10000))\n",
    "\n",
    "# ab = 'A'\n",
    "# for i, row in df123.iterrows():\n",
    "#     if row['AOD'] == ab:\n",
    "#         row.ABNORMAL = True\n",
    "#     df234.append(row)\n",
    "#     ab = row['AOD']\n",
    "    \n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(df123.head(100))\n",
    "\n",
    "# #------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARP 경로 파생변수 생성\n",
    "df['ARPODP'] = df['ARP'] + '_' + df['ODP']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "\n",
    "df['Diff'] = (pd.to_datetime(df['ATT'],format= '%H:%M') - pd.to_datetime(df['STT'],format= '%H:%M')).dt.seconds.astype('int64')\n",
    "\n",
    "# STT와 ATT 격차 큰 순대로 정렬\n",
    "df = df.sort_values(by=['Diff'], ascending=False)\n",
    "\n",
    "########################################################################출발\n",
    "# 딜레이가 최대 5시간이라고 가정했을 때, --> 즉, 2시간 초과한 딜레이는 wrong값이라 가정\n",
    "max_delay_hour = 5\n",
    "max_delay = max_delay_hour * 3600 # seconds\n",
    "\n",
    "# 출발비행기의 경우, 조금이라도 출발이 빠른 건 wrong data라 판단.\n",
    "# 7200보다 큰 값을 가지는 Diff 데이터 wrong 값 처리\n",
    "df = df[((df['Diff'] <= max_delay) & (df['AOD']=='D')) | (df['AOD']=='A')]\n",
    "\n",
    "df.head(100)\n",
    "\n",
    "########################################################################도착\n",
    "#이정도는 늦게 도착해도 O\n",
    "#2시간은 예상보다 늦게도착할 수 있다. 그 이상은 말이안된다\n",
    "max_delay_hour_arr = 5\n",
    "max_delay_arr = max_delay_hour_arr * 3600 # seconds\n",
    "\n",
    "#몇분 일찍도착해도 O\n",
    "#30분은 예상보다 빨리도착할 수 있음. 그거보다 빨리도착하는 건 말이 안됨\n",
    "min_delay = 30*60\n",
    "min_delay = 86400 - min_delay  # 86400(24시간)보다 위인거만 살려놓기\n",
    "df = df[(df['AOD']=='D') |((df['Diff'] <= max_delay_arr) & (df['AOD']=='A')) | ((df['AOD']=='A')& (df['Diff'] >= min_delay )) ]\n",
    "df.loc[df['Diff'] >=min_delay, 'Diff'] = df.loc[df['Diff'] >=min_delay, 'Diff']  - 86400\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Check the numerical data\n",
    "# numerical_feature = [col for col in df.columns if df[col].dtypes == 'int64']\n",
    "\n",
    "# print(numerical_feature)\n",
    "\n",
    "# def dist_box(df, feature_list):\n",
    "#     for col in feature_list:\n",
    "#         plt.figure(figsize=(15, 5))\n",
    "#         sns.distplot(df.loc[df[col].notnull(), col])\n",
    "#         plt.title(col)\n",
    "#         plt.show()\n",
    "        \n",
    "#         df[col].plot(kind='box', color='red')\n",
    "#         plt.show()\n",
    "        \n",
    "# print('*'*50)\n",
    "# print('All')\n",
    "# dist_box(df, numerical_feature)\n",
    "# print('*'*50)\n",
    "# print('Arrive')\n",
    "# dist_box(df[df['AOD'] == 'A'], numerical_feature)\n",
    "# print('*'*50)\n",
    "# print('Departure')\n",
    "# dist_box(df[df['AOD'] == 'D'], numerical_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간에서 시 데이터만 추출 ==> 분은 영향을 줄임.\n",
    "df['ATT'] = pd.to_datetime(df['ATT'],format= '%H:%M').dt.hour\n",
    "df['STT'] = pd.to_datetime(df['STT'],format= '%H:%M').dt.hour\n",
    "\n",
    "############ 잠시 삭제\n",
    "# 일단 FLT는 처리할 방법이 없어서 삭제해놓음\n",
    "df.drop(['FLT'], axis=1, inplace = True)\n",
    "#날짜 년, 일 제거\n",
    "df.drop(['DAY'], axis=1, inplace = True)\n",
    "\n",
    "df.drop(['ATT','Diff'], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data --> one hot encoding\n",
    "\n",
    "def one_hot_dummies(df, *args):\n",
    "    for col in args:\n",
    "        one_hot_col = pd.get_dummies(df[col])\n",
    "        new_col = [col + '_' + str(s) for s in one_hot_col.columns]\n",
    "        one_hot_col.columns = new_col\n",
    "        df = df.drop([col], axis = 1)\n",
    "        df = df.join(one_hot_col)d\n",
    "\n",
    "    return df\n",
    "\n",
    "df = one_hot_dummies(df, 'ARPODP')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Target 레이블링\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# DLY도 1과 0으로 데이터 처리\n",
    "le = preprocessing.LabelEncoder()\n",
    "df[['DLY']] = le.fit_transform(df[['DLY']])\n",
    "df[['ARP']] = le.fit_transform(df[['ARP']])\n",
    "df[['ODP']] = le.fit_transform(df[['ODP']])\n",
    "df[['FLO']] = le.fit_transform(df[['FLO']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도착, 출발 데이터 분리\n",
    "df_A = df[df['AOD']=='A']\n",
    "df_D = df[df['AOD']=='D']\n",
    "\n",
    "# AOD column삭제 \n",
    "df_A = df_A.drop(['AOD'],axis = 1)\n",
    "df_D = df_D.drop(['AOD'],axis = 1)\n",
    "\n",
    "df_A.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTestSet(df):\n",
    "    X = df.drop(['DLY'], axis = 1)\n",
    "    y = df['DLY']\n",
    "        \n",
    "    X_tr, X_t, y_tr, y_t = train_test_split(X,y, test_size= 0.3, random_state = 42)\n",
    "    \n",
    "    print(\"X_train set--------------------\")\n",
    "    print(\"Shape:\",X_tr.shape)\n",
    "    print(\"Target:\")\n",
    "    print(y_tr.value_counts())\n",
    "    print()\n",
    "      \n",
    "    print(\"X_test set info-----------------\")\n",
    "    print(\"Shape:\",X_t.shape)\n",
    "    print(\"Target:\")\n",
    "    print(y_t.value_counts())\n",
    "    print()\n",
    "\n",
    "    return [X_tr, X_t, y_tr, y_t]\n",
    "\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = makeTestSet(df_A)\n",
    "X_train_D, X_test_D, y_train_D, y_test_D = makeTestSet(df_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# 날씨 데이터 추가 후 주석 제거할 것.\n",
    "\n",
    "# # scaler - weather data\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# df[['cloudTotal', 'dew', 'hpa', 'seeHpa', 'temp', 'visible', 'windSpeed']] = scaler.fit_transform(df[['cloudTotal', 'dew', 'hpa', 'seeHpa', 'temp', 'visible', 'windSpeed']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['visible']==0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------변수 중요도 확인하고 상위 OO개 남기기 -------------------\n",
    "\n",
    "def feature_importance(X_train, y_train, X_test, y_test):\n",
    "        \n",
    "    #### Skew Data처리할거면 주석 해제하기!!\n",
    "    #X_train, y_train = imbalance(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    log_rg = LogisticRegression().fit(X_train, y_train)\n",
    "    cross_val_score(log_rg, X_train, y_train, cv=5)\n",
    "    log_rg.score(X_test, y_test)\n",
    "    print(classification_report(y_test, log_rg.predict(X_test)))\n",
    "\n",
    "    # X column 개수 출력\n",
    "    #print(len(X.columns)) \n",
    "\n",
    "    # 변수 중요도 \n",
    "    fi = pd.DataFrame(zip(X_train.columns.values, abs(log_rg.coef_.ravel())))\n",
    "    fi.columns = ['feature', 'coef']\n",
    "    fi.sort_values(\"coef\", ascending=False, inplace=True)\n",
    "    fi = fi.reset_index().drop(['index'], axis=1)\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(fi)\n",
    "\n",
    "    for index, val in enumerate(fi.iloc[:, 1]):\n",
    "        if val < 0.1:\n",
    "            X_train.drop([fi.iloc[index, 0]], axis = 1, inplace = True)\n",
    "            X_test.drop([fi.iloc[index, 0]], axis = 1, inplace = True)   \n",
    "    return\n",
    "\n",
    "feature_importance(X_train_A, y_train_A, X_test_A, y_test_A)\n",
    "feature_importance(X_train_D, y_train_D, X_test_D, y_test_D)\n",
    "print(len(X_train_A.columns))\n",
    "print(len(X_test_A.columns))\n",
    "print(len(X_train_D.columns))\n",
    "print(len(X_test_D.columns))\n",
    "\n",
    "#--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalance (X_train, y_train):\n",
    "\n",
    "    # 모델설정\n",
    "    sm = SMOTE(ratio='auto', kind='regular')\n",
    "\n",
    "    # train데이터를 넣어 복제함\n",
    "    X_resampled, y_resampled = sm.fit_sample(X_train,list(y_train))\n",
    "\n",
    "    print('After OverSampling, the shape of train_X: {}'.format(X_resampled.shape))\n",
    "    print('After OverSampling, the shape of train_y: {} \\n'.format(X_resampled.shape))\n",
    "\n",
    "    print(\"After OverSampling, counts of label '1': {}\".format(sum(y_resampled==1)))\n",
    "    print(\"After OverSampling, counts of label '0': {}\".format(sum(y_resampled==0)))\n",
    "    \n",
    "    return [X_resampled, y_resampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under sampling 부분 --> 사용시 runModel의 주석을 풀어 사용해야함.\n",
    "\n",
    "from imblearn.under_sampling import *\n",
    "def under_sampling(X_train, y_train):\n",
    "    X_resampled, y_resampled = RandomUnderSampler(random_state=0).fit_sample(X_train, y_train)\n",
    "    X_resampled = pd.DataFrame(X_resampled)\n",
    "    X_resampled.columns = X_train_D.columns\n",
    "    y_resampled = pd.DataFrame(y_resampled)\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids # doctest: +NORMALIZE_WHITESPACE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "def another_under_sampling(X_train, y_train):\n",
    "    sampler = EditedNearestNeighbours(ratio={0:40000, 1:20000})\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve그리기\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \n",
    "    \n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_heatmap(y_true, y_pred):\n",
    "    data = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.set(font_scale=1.4)#for label size\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid Search를 통한 하이퍼 파라미터 최적화 부분 --> 아직 적용하지 않음.\n",
    "# Colab을 통해 적용에 문제가 없나 실험중에 있음. \n",
    "\n",
    "def optimizationPrams():\n",
    "    param_grid = { \n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    }\n",
    "    rfc=RandomForestClassifier(random_state=42)\n",
    "\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "\n",
    "    return CV_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel (X_train, y_train, X_test, y_test, base = True):\n",
    "    \n",
    "    #X_train, y_train = under_sampling(X_train, y_train)\n",
    "    \n",
    "     ## Skew Data처리할거면 주석 풀기!!\n",
    "    X_train, y_train = imbalance(X_train, y_train)\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    if base ==True:\n",
    "         models.append(('XGB', XGBClassifier()))\n",
    "    else:\n",
    "#         models.append(('LR', LogisticRegression()))\n",
    "#         models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "#         models.append(('KNN', KNeighborsClassifier()))\n",
    "#         models.append(('CART', DecisionTreeClassifier()))\n",
    "#         models.append(('NB', GaussianNB()))\n",
    "        models.append(('RF', RandomForestClassifier(max_depth=4, n_estimators=100, random_state=0)))\n",
    "#         models.append(('SVM', SVC(gamma='auto')))\n",
    "#         models.append(('XGB', XGBClassifier()))\n",
    "\n",
    "    \n",
    "    # 평가\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = 'recall'\n",
    "\n",
    "    seed = 7\n",
    "    for name, model in models:\n",
    "        # K-Fold\n",
    "#         kfold = KFold(n_splits=10, random_state=seed)\n",
    "#         cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "#         results.append(cv_results)\n",
    "#         names.append(name)\n",
    "#         msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#         print(msg)\n",
    "\n",
    "        # Hold out \n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = pd.Series(model.predict(X_test))\n",
    "\n",
    "        # Resets index to compare original test data with predicted data\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "        y_predict = y_predict.reset_index(drop=True)\n",
    "\n",
    "#         plt.figure(figsize=(15, 5))\n",
    "#         plt.scatter(range(y_test.shape[0]), y_test, c='gray')\n",
    "#         plt.scatter(range(y_predict.shape[0]), y_predict , c='r')\n",
    "#         diff = abs(y_test - y_predict)\n",
    "#         plt.bar(range(diff.shape[0]), diff, color='gray')\n",
    "#         plt.title('Result - Original comparsion')\n",
    "#         plt.legend(['Original', 'Predict'])\n",
    "#         plt.show()\n",
    "\n",
    "        print(model.score(X_test, y_test))\n",
    "        print('-' * 50)\n",
    "        \n",
    "        #--------ROC Curve-----------------\n",
    "        probs = model.predict_proba(X_test)\n",
    "        probs = probs[:, 1]\n",
    "        auc = roc_auc_score(y_test, probs)\n",
    "        print('AUC: %.2f' % auc)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "        plot_roc_curve(fpr, tpr)\n",
    "        #-----------------------------------\n",
    "        \n",
    "        #-------- Confusion matrix heatmap -----------------\n",
    "        confusion_matrix_heatmap(y_test, y_predict)\n",
    "        print(classification_report(y_test, y_predict))\n",
    "        #-----------------------------------\n",
    "        \n",
    "             \n",
    "#      # boxplot algorithm comparison\n",
    "#     fig = plt.figure(figsize=(11,6))\n",
    "#     fig.suptitle('Algorithm Comparison')\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     plt.boxplot(results)\n",
    "#     ax.set_xticklabels(names)\n",
    "#     plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# True면 base algorithm만 실행하겠다 (base algorithm : Random Forest)\n",
    "# False면 모든 알고리즘을 실행하겠다.\n",
    "runModel (X_train_D,y_train_D, X_test_D, y_test_D, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True면 base algorithm만 실행하겠다 (base algorithm : Random Forest)\n",
    "# False면 모든 알고리즘을 실행하겠다.\n",
    "runModel (X_train_A,y_train_A, X_test_A, y_test_A, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
