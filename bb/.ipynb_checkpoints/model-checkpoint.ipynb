{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import codecs\n",
    "import csv\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDT_YY</th>\n",
       "      <th>SDT_MM</th>\n",
       "      <th>SDT_DD</th>\n",
       "      <th>SDT_DY</th>\n",
       "      <th>ARP</th>\n",
       "      <th>ODP</th>\n",
       "      <th>FLO</th>\n",
       "      <th>FLT</th>\n",
       "      <th>REG</th>\n",
       "      <th>AOD</th>\n",
       "      <th>IRR</th>\n",
       "      <th>STT</th>\n",
       "      <th>ATT</th>\n",
       "      <th>DLY</th>\n",
       "      <th>DRR</th>\n",
       "      <th>CNL</th>\n",
       "      <th>CNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>A</td>\n",
       "      <td>A1901</td>\n",
       "      <td>SEw3Nzc2</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:10</td>\n",
       "      <td>6:18</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>A</td>\n",
       "      <td>A1905</td>\n",
       "      <td>SEw4MjM2</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:15</td>\n",
       "      <td>6:25</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>L</td>\n",
       "      <td>L1751</td>\n",
       "      <td>SEw4MjM3</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:20</td>\n",
       "      <td>6:30</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>F</td>\n",
       "      <td>F1201</td>\n",
       "      <td>SEw4MjA3</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:25</td>\n",
       "      <td>6:34</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>일</td>\n",
       "      <td>ARP3</td>\n",
       "      <td>ARP1</td>\n",
       "      <td>A</td>\n",
       "      <td>A1900</td>\n",
       "      <td>SEw3NzAz</td>\n",
       "      <td>D</td>\n",
       "      <td>N</td>\n",
       "      <td>6:30</td>\n",
       "      <td>6:37</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDT_YY  SDT_MM  SDT_DD SDT_DY   ARP   ODP FLO    FLT       REG AOD IRR  \\\n",
       "0    2017       1       1      일  ARP1  ARP3   A  A1901  SEw3Nzc2   D   N   \n",
       "1    2017       1       1      일  ARP1  ARP3   A  A1905  SEw4MjM2   D   N   \n",
       "2    2017       1       1      일  ARP1  ARP3   L  L1751  SEw4MjM3   D   N   \n",
       "3    2017       1       1      일  ARP1  ARP3   F  F1201  SEw4MjA3   D   N   \n",
       "4    2017       1       1      일  ARP3  ARP1   A  A1900  SEw3NzAz   D   N   \n",
       "\n",
       "    STT   ATT DLY  DRR CNL  CNR  \n",
       "0  6:10  6:18   N  NaN   N  NaN  \n",
       "1  6:15  6:25   N  NaN   N  NaN  \n",
       "2  6:20  6:30   N  NaN   N  NaN  \n",
       "3  6:25  6:34   N  NaN   N  NaN  \n",
       "4  6:30  6:37   N  NaN   N  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin = pd.read_csv('AFSNT.csv', encoding=\"cp949\")\n",
    "origin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin.rename(columns={'SDT_YY':'Year', 'SDT_MM':'Month', 'SDT_DD':'DAY'}, inplace=True)\n",
    "\n",
    "#### 'STT'의 시간단위만 추출해 'hour'에 저장\n",
    "origin['hour']=pd.to_datetime(origin['STT'],format= '%H:%M').dt.hour\n",
    "\n",
    "\n",
    "\n",
    "####'SDT_DY'를 categorical 데이터로 수정\n",
    "\n",
    "## Todo: 요일은 계속 원핫???\n",
    "one_hot_dy = pd.get_dummies(origin['SDT_DY'])\n",
    "origin = origin.drop(['SDT_DY'],axis = 1)\n",
    "origin = origin.join(one_hot_dy)\n",
    "origin.rename(columns={\"일\":\"Sun\",\"월\":\"Mon\",\"화\":\"Tue\",\"수\":\"Wed\",\"목\":\"Thu\",\"금\":\"Fri\",\"토\":\"SAT\",\"일\":\"Sun\"                    \n",
    "                  }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 한 자리수 데이터를 앞에 '0'을 붙여 두 자리로 변환\n",
    "def changeDate(data):\n",
    "    data=str(data)\n",
    "    if len(data)==1:\n",
    "        data=\"0\"+data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####군공항을 제외한 날씨 데이터를 다운받는 함수(공항공사 데이터)\n",
    "\n",
    "def downloadAirport(yy,mm,area):\n",
    "    mm=changeDate(mm)\n",
    "    yy=str(yy)\n",
    "    url='http://amoapi.kma.go.kr/amoApi/air_stcs?icao='+area+'&yyyymm='+yy+mm\n",
    "    response = urllib.request.urlopen(url)\n",
    "    cr = csv.reader(codecs.iterdecode(response, 'utf-8'))\n",
    "    \n",
    "    #### url로 읽어와 데이터 프레임에 저장\n",
    "    temp=[]\n",
    "    for line in cr:\n",
    "        temp.append(line)\n",
    "    \n",
    "    labels=temp[0]\n",
    "    weather=pd.DataFrame.from_records(temp[1:],columns=labels)\n",
    "    \n",
    "    weather[\"TM\"]=weather[\"TM\"].astype(\"str\")\n",
    "\n",
    "    weather[\"Year\"]=weather[\"TM\"].str.slice(0,4)\n",
    "    weather[\"Month\"]=weather[\"TM\"].str.slice(4,6)\n",
    "    weather[\"DAY\"]=weather[\"TM\"].str.slice(6,8)\n",
    "    hh=weather[\"TM\"].str.slice(8,10)\n",
    "    weather['hour']=hh\n",
    "\n",
    "    weather['hour']= weather['hour'].astype('int')\n",
    "    weather['hour']=weather['hour'].replace(24,0)\n",
    "    \n",
    "    #### 분석에 필요하지 않은 column 삭제\n",
    "    weather.drop(columns=[\"TM\"], axis=1, inplace=True)\n",
    "    weather.drop(columns=[\"WD\",\"WS_GST\",\"RVR1\",\"RVR2\",\"RVR3\",\"RVR4\",\"CLA_1LYR\"\n",
    "               ,\"BASE_1LYR\",\"CLF_1LYR\",\"CLA_2LYR\",\"BASE_2LYR\",\"CLF_2LYR\",\n",
    "               \"CLA_3LYR\",\"BASE_3LYR\",\"CLF_3LYR\",\"CLA_4LYR\",\"BASE_4LYR\",\"CLF_4LYR\"], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    #### 기록이 안 되어 있는 데이터에 '0'을 채워줌\n",
    "    weather=weather.fillna(0)\n",
    "    weather[\"Year\"]=weather[\"Year\"].astype(\"int\")\n",
    "    weather[\"Month\"]=weather[\"Month\"].astype(\"int\")\n",
    "    weather[\"DAY\"]=weather[\"DAY\"].astype(\"int\")\n",
    "    \n",
    "    return weather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 항공데이터에서 제공하지 않는 군공항 데이터를 기상청 날씨데이터를 사용해 다운받는 함수(기상청 csv)\n",
    "def downloadWeather(year):\n",
    "    filename=\"data/\"+str(year)+\".csv\"\n",
    "    weather=pd.read_csv(filename,encoding=\"cp949\")\n",
    "    \n",
    "    #### 일시의 데이트타입과 시간을 따로 저장\n",
    "    weather[\"일시\"] = weather[\"일시\"].astype('str')\n",
    "    date=weather[\"일시\"].str.split(expand=True)\n",
    "    day=date[0].str.split(\"-\",expand=True)\n",
    "    \n",
    "    weather[\"Year\"]=day[0]\n",
    "    weather[\"Month\"]=day[1]\n",
    "    weather[\"DAY\"]=day[2]\n",
    "    \n",
    "    \n",
    "    weather[\"hour\"]=date[1]\n",
    "    \n",
    "    #### 일시 drop(변경 전 데이터)\n",
    "    weather.drop(columns=['일시'], axis=1, inplace=True)\n",
    "    #### 분석에 필요하지 않은 column 삭제\n",
    "    weather = weather.drop(['지면온도(°C)',\"지면온도 QC플래그\",\"5cm 지중온도(°C)\",\"10cm 지중온도(°C)\",\"20cm 지중온도(°C)\",\"기온 QC플래그\",\n",
    "                            \"강수량 QC플래그\",\"풍속 QC플래그\",\"풍향(16방위)\",\"풍향 QC플래그\",\"습도 QC플래그\",\"현지기압 QC플래그\",\n",
    "                            \"해면기압 QC플래그\",\"중하층운량(10분위)\",\"운형(운형약어)\",\"최저운고(100m )\",\"지면상태(지면상태코드)\",\n",
    "                           \"적설(cm)\",\"3시간신적설(cm)\", \"30cm 지중온도(°C)\",\"일조(hr)\",\"일조 QC플래그\",\"일사(MJ/m2)\"],axis = 1)\n",
    "    \n",
    "    #### 한글을 사용함으로써 발생하는 오류를 방지하기 위해 column명들을 영어로 rename\n",
    "    weather.rename(columns={\"지점\" : \"area\", \"기온(°C)\":\"temp\" ,\"강수량(mm)\":\"rain\", \"풍속(m/s)\":\"windSpeed\",\n",
    "                            \"습도(%)\":\"hum\",\"증기압(hPa)\":\"Vapor\",\"이슬점온도(°C)\":\"dew\",\"현지기압(hPa)\":\"hpa\",\n",
    "                            \"해면기압(hPa)\":\"seeHpa\",\"시정(10m)\":\"visible\",\"전운량(10분위)\":\"cloudTotal\",\n",
    "                            \"현상번호(국내식)\":\"weatherCode\"}, inplace=True)\n",
    "    \n",
    "    #### merge시에 타입이 같아야 하므로 데이터타입을 int형으로 변환\n",
    "    weather[\"hour\"]=weather[\"hour\"].astype(\"str\")\n",
    "    weather[\"hour\"]=weather[\"hour\"].str.split(\":\",expand=True)[0]\n",
    "    weather[\"hour\"]=weather[\"hour\"].astype(\"int\")\n",
    "    \n",
    "    weather[\"Year\"]=weather[\"Year\"].astype(\"int\")\n",
    "    weather[\"Month\"]=weather[\"Month\"].astype(\"int\")\n",
    "    weather[\"DAY\"]=weather[\"DAY\"].astype(\"int\")\n",
    "    \n",
    "    #### 기록이 안 되어 있는 데이터에 '0'을 채워줌    \n",
    "    weather=weather.fillna(0)\n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 군공항을 제외한 항공들의 날씨 데이터와 기상 정보를 merge하는 함수\n",
    "def mergeAirportData():\n",
    "    df_all=pd.DataFrame()\n",
    "    #### 군공항을 제외한 항공들만 저장\n",
    "    temp=origin[(origin.ARP==\"ARP1\") | (origin.ARP==\"ARP3\")| (origin.ARP==\"ARP5\") | (origin.ARP==\"ARP7\") \n",
    "                | (origin.ARP==\"ARP9\")| (origin.ARP==\"ARP10\") ]\n",
    "    \n",
    "    elements,count=np.unique(temp[\"ARP\"],return_counts=True)\n",
    "    \n",
    "    #### 각각의 공항에 대하여 월별로 데이터를 찾아 merge하고 DataFrame형태로 저장하는 loop문\n",
    "    for i in range(len(elements)):\n",
    "        df_areaD=pd.DataFrame()\n",
    "        arp=elements[i]\n",
    "        area={\"ARP1\":\"RKSS\",\"ARP3\":\"RKPC\",\"ARP5\":\"RKPU\",\n",
    "              \"ARP7\":\"RKJB\",\"ARP9\":\"RKJY\",\"ARP10\":\"RKNY\"}.get(arp)\n",
    "        df_areaD=temp[temp[\"ARP\"]==arp]\n",
    "        \n",
    "        for j in range(3):\n",
    "            year=2017+j\n",
    "            for k in range(12):\n",
    "                #### 2019년은 데이터가 6월까지만 존재함\n",
    "                if year==2019:\n",
    "                    if k>=6:\n",
    "                        break;\n",
    "                month=1+k\n",
    "                df_date=df_areaD[(df_areaD[\"Year\"]==year) & (df_areaD[\"Month\"]==month)]\n",
    "                weather=downloadAirport(year,month,area)\n",
    "                df_new=pd.merge(df_areaD,weather,on=[\"Year\",\"Month\",\"DAY\",\"hour\"])\n",
    "                \n",
    "                if i==0 and j==0 and k==0:\n",
    "                    df_all=df_new.copy()\n",
    "                else:\n",
    "                    df_all=df_all.append(df_new)\n",
    "                    \n",
    "    #### 기상청데이터와 연결 하기 위해 rename                \n",
    "    df_all.rename(columns={'WSPD':'windSpeed','VIS':\"visible\",\"TMP\":\"temp\",\n",
    "                      \"TD\":\"dew\",'PS':'hpa','PA':'seeHpa','RN':'rain','HM':'hum',\n",
    "                        'CA_TOT':'cloudTotal','WC':\"weatherCode\"}, inplace=True)\n",
    "    \n",
    "    \n",
    "    #### 기상청에서 받아온 파일과 함께 저장하기 위해 항공공사의 데이터의 단위를 조정함\n",
    "    df_all['temp']=df_all['temp'].astype(\"float\")/10\n",
    "    df_all['hpa']=df_all['hpa'].astype(\"float\")/10\n",
    "    df_all['seeHpa']=df_all['seeHpa'].astype(\"float\")/10\n",
    "    df_all['dew']=df_all['dew'].astype(\"float\")/10\n",
    "    df_all['windSpeed']=df_all['windSpeed'].astype(\"float\")*1852/3600\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 군공항에 대해 기상청을 통해 불러온 날씨 데이터와 기상 정보를 merge하는 함수\n",
    "def mergeWeatherData():\n",
    "    temp=origin[(origin.ARP==\"ARP2\") | (origin.ARP==\"ARP4\")| (origin.ARP==\"ARP6\") | (origin.ARP==\"ARP8\") | (origin.ARP==\"ARP11\")\n",
    "                | (origin.ARP==\"ARP12\")| (origin.ARP==\"ARP13\")| (origin.ARP==\"ARP14\")|(origin.ARP==\"ARP15\")]\n",
    "    \n",
    "    elements,count=np.unique(temp[\"ARP\"],return_counts=True)\n",
    "    \n",
    "    #### 각각의 공항에 대하여 연별로 데이터를 찾아 merge하고 저장하는 loop문\n",
    "    for i in range(3):\n",
    "        df_areaD=pd.DataFrame()\n",
    "        year=2017+i\n",
    "        weather=downloadWeather(year)\n",
    "        df_yearD=origin[origin[\"Year\"]==year]\n",
    "        for j in range(len(elements)):\n",
    "            arp=elements[j]\n",
    "            area={\"ARP2\":159,\"ARP4\":143,\"ARP6\":131, \"ARP8\":156,\n",
    "                  \"ARP11\":138,\"ARP12\":192, \"ARP13\":140,\"ARP14\":114,\"ARP15\":112}.get(arp)\n",
    "            \n",
    "            df_areaD=df_yearD[df_yearD[\"ARP\"]==arp]\n",
    "            df_new=pd.DataFrame()\n",
    "            weatherT=weather[weather[\"area\"]==area]\n",
    "           \n",
    "            df_new=pd.merge(df_areaD,weatherT,on=[\"DAY\",\"hour\",\"Year\",\"Month\"])\n",
    "        \n",
    "            if i==0 and j==0:\n",
    "                df_all=df_new.copy()\n",
    "            else:\n",
    "                df_all=df_all.append(df_new)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airport=mergeAirportData()\n",
    "df_nonAirport=mergeWeatherData()\n",
    "\n",
    "df_weather=df_airport.append(df_nonAirport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.drop(['area','Vapor', 'hour'], axis = 1, inplace=True)\n",
    "#### 데이터가 입력되어있지 않은 것들을 '0'으로 대체함\n",
    "df_weather['visible']= df_weather['visible'].replace(\"\", 0)\n",
    "df_weather['hum']= df_weather['hum'].replace(\"\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 기상정보와 날씨 데이터를 합친 DataFrame을 파일로 저장\n",
    "df_weather.to_csv(\"weatherFinal.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 데이터\n",
    "df = pd.read_csv('weatherFinal.CSV', encoding=\"cp949\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.IRR != \"Y\"] # 부정기 없애기 \n",
    "df = df[df.CNL != \"Y\"]\n",
    "\n",
    "# 비행기 취소와 관련된 Column 삭제\n",
    "df.drop(columns=['CNL', 'CNR'], axis=1, inplace=True)\n",
    "\n",
    "# 사용되지 않을 것 같은 데이터 일단 삭제\n",
    "df.drop(columns=['REG', 'IRR'], axis=1, inplace=True)\n",
    "\n",
    "# 딜레이 이유 (나중에 쓰일 듯)\n",
    "df.drop(columns=['DRR'], axis=1, inplace=True)\n",
    "\n",
    "############# 날씨 데이터 추가 후 주석 제거할 것.\n",
    "# 날씨 관련 안쓰는 feature 삭제\n",
    "df.drop(columns=['rain', 'weatherCode'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT (actual time data)가 널 값인 레코드 삭제\n",
    "df = df[pd.notnull(df['ATT'])]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ARP와 ODP가 같은 데이터 --> Wrong data => 삭제\n",
    "df.drop(df[df['ARP'] == df['ODP']].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- fog 모델 돌리기 --------------\n",
    "\n",
    "## INPUT : 'temp', 'hum', 'dew', 'windSpeed' 4가지 Column의 DataFrame\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def fogPreProcessing (df):\n",
    "    # 비어있는 값 0으로 대체\n",
    "    #print(df.isnull().sum())\n",
    "    df.fillna(0, inplace = True)\n",
    "  \n",
    "    # MinMaxScaling\n",
    "    scaler = MinMaxScaler()\n",
    "    df[['hum', 'dew','temp','windSpeed']] = scaler.fit_transform(df[['hum', 'dew','temp','windSpeed']])\n",
    "  \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fog = df[[\"temp\",\"hum\",\"dew\",\"windSpeed\"]]\n",
    "\n",
    "fog = fogPreProcessing(fog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# 저장된 모델 불러오기\n",
    "clf_from_joblib = joblib.load('fogmodel.pkl') \n",
    "\n",
    "# 저장된 모델로 예측하기\n",
    "#clf_from_joblib.predict(fog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측할 때 확률로가져오기!\n",
    "result = clf_from_joblib.predict_proba(fog)\n",
    "\n",
    "fog_column = []\n",
    "\n",
    "# fog_column에 확률값 저장\n",
    "for i in result:\n",
    "    fog_column.append(i[1])\n",
    "    \n",
    "print(\"fog_column :\",len(fog_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fog'] = fog_column\n",
    "\n",
    "df.drop(columns=['hum', 'dew','temp','windSpeed'], axis=1, inplace=True)\n",
    "#------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARP 경로 파생변수 생성\n",
    "df['ARPODP'] = df['ARP'] + '_' + df['ODP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "\n",
    "df['Diff'] = (pd.to_datetime(df['ATT'],format= '%H:%M') - pd.to_datetime(df['STT'],format= '%H:%M')).dt.seconds.astype('int64')\n",
    "\n",
    "# STT와 ATT 격차 큰 순대로 정렬\n",
    "df = df.sort_values(by=['Diff'], ascending=False)\n",
    "\n",
    "########################################################################출발\n",
    "# 딜레이가 최대 5시간이라고 가정했을 때, --> 즉, 2시간 초과한 딜레이는 wrong값이라 가정\n",
    "max_delay_hour = 5\n",
    "max_delay = max_delay_hour * 3600 # seconds\n",
    "\n",
    "# 출발비행기의 경우, 조금이라도 출발이 빠른 건 wrong data라 판단.\n",
    "# 7200보다 큰 값을 가지는 Diff 데이터 wrong 값 처리\n",
    "df = df[((df['Diff'] <= max_delay) & (df['AOD']=='D')) | (df['AOD']=='A')]\n",
    "\n",
    "\n",
    "########################################################################도착\n",
    "#이정도는 늦게 도착해도 O\n",
    "#2시간은 예상보다 늦게도착할 수 있다. 그 이상은 말이안된다\n",
    "max_delay_hour_arr = 5\n",
    "max_delay_arr = max_delay_hour_arr * 3600 # seconds\n",
    "\n",
    "#몇분 일찍도착해도 O\n",
    "#30분은 예상보다 빨리도착할 수 있음. 그거보다 빨리도착하는 건 말이 안됨\n",
    "min_delay = 30*60\n",
    "min_delay = 86400 - min_delay  # 86400(24시간)보다 위인거만 살려놓기\n",
    "df = df[(df['AOD']=='D') |((df['Diff'] <= max_delay_arr) & (df['AOD']=='A')) | ((df['AOD']=='A')& (df['Diff'] >= min_delay )) ]\n",
    "df.loc[df['Diff'] >=min_delay, 'Diff'] = df.loc[df['Diff'] >=min_delay, 'Diff']  - 86400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 + 분 합침.\n",
    "df['ATT']= (pd.to_datetime(df['ATT'],format= '%H:%M').dt.hour).astype(str) + (pd.to_datetime(df['ATT'],format= '%H:%M').dt.minute).astype(str)\n",
    "df['time']= (pd.to_datetime(df['STT'],format= '%H:%M').dt.hour).astype(str) + (pd.to_datetime(df['STT'],format= '%H:%M').dt.minute).astype(str)\n",
    "\n",
    "\n",
    "\n",
    "df.drop(['FLT'], axis=1, inplace = True)\n",
    "#날짜 년, 일 제거\n",
    "df.drop(['DAY'], axis=1, inplace = True)\n",
    "\n",
    "df.drop(['ATT','STT','Diff'], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time']= df['time'].astype('int')\n",
    "scaler = MinMaxScaler()\n",
    "df[['time']] = scaler.fit_transform(df[['time']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Target 레이블링\n",
    "\n",
    "from sklearn import preprocessing\n",
    "# DLY도 1과 0으로 데이터 처리\n",
    "le = preprocessing.LabelEncoder()\n",
    "df[['DLY']] = le.fit_transform(df[['DLY']])\n",
    "df[['ARP']] = le.fit_transform(df[['ARP']])\n",
    "df[['ODP']] = le.fit_transform(df[['ODP']])\n",
    "df[['FLO']] = le.fit_transform(df[['FLO']])\n",
    "df[['ARPODP']] = le.fit_transform(df[['ARPODP']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도착, 출발 데이터 분리\n",
    "df_A = df[df['AOD']=='A']\n",
    "df_D = df[df['AOD']=='D']\n",
    "\n",
    "# AOD column삭제 \n",
    "df_A = df_A.drop(['AOD'],axis = 1)\n",
    "df_D = df_D.drop(['AOD'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTestSet(df):\n",
    "    X = df.drop(['DLY'], axis = 1)\n",
    "    y = df['DLY']\n",
    "        \n",
    "    X_tr, X_t, y_tr, y_t = train_test_split(X,y, test_size= 0.3, random_state = 42)\n",
    "    \n",
    "    print(\"X_train set--------------------\")\n",
    "    print(\"Shape:\",X_tr.shape)\n",
    "    print(\"Target:\")\n",
    "    print(y_tr.value_counts())\n",
    "    print()\n",
    "      \n",
    "    print(\"X_test set info-----------------\")\n",
    "    print(\"Shape:\",X_t.shape)\n",
    "    print(\"Target:\")\n",
    "    print(y_t.value_counts())\n",
    "    print()\n",
    "\n",
    "    return [X_tr, X_t, y_tr, y_t]\n",
    "\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = makeTestSet(df_A)\n",
    "X_train_D, X_test_D, y_train_D, y_test_D = makeTestSet(df_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve그리기\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \n",
    "    \n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_heatmap(y_true, y_pred):\n",
    "    data = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.set(font_scale=1.4)#for label size\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel (X_train, y_train, X_test, y_test, base = True):\n",
    "    \n",
    "    #X_train, y_train = under_sampling(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    if base ==True:\n",
    "          models.append(('XGB', XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                        silent=True, nthread=1,subsample=1.0,min_child_weight=5,max_depth=5,gamma=5,colsample_bytree=0.6)))\n",
    "    \n",
    "    # 평가\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = 'recall'\n",
    "\n",
    "    seed = 7\n",
    "    for name, model in models:\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = pd.Series(model.predict(X_test))\n",
    "\n",
    "        # Resets index to compare original test data with predicted data\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "        y_predict = y_predict.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        print(model.score(X_test, y_test))\n",
    "        print('-' * 50)\n",
    "        \n",
    "        #--------ROC Curve-----------------\n",
    "        probs = model.predict_proba(X_test)\n",
    "        probs = probs[:, 1]\n",
    "        auc = roc_auc_score(y_test, probs)\n",
    "        print('AUC: %.2f' % auc)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "        plot_roc_curve(fpr, tpr)\n",
    "        #-----------------------------------\n",
    "        \n",
    "        #-------- Confusion matrix heatmap -----------------\n",
    "        confusion_matrix_heatmap(y_test, y_predict)\n",
    "        print(classification_report(y_test, y_predict))\n",
    "        #-----------------------------------\n",
    "        \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runModel (X_train_A,y_train_A, X_test_A, y_test_A, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runModel (X_train_D,y_train_D, X_test_D, y_test_D, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
